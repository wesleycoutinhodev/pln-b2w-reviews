{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1_-l7Xztx0haKqfyMue6CXOl3fCFZbUbL",
      "authorship_tag": "ABX9TyNzYkbilFiWg/dWzjh5YHdM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wesleycoutinhodev/pln-b2w-reviews/blob/main/notebooks/Operacoes_1_2_3_Tratamento_Dados.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Notebook: Operacoes_1_2_3_Tratamento_Dados.ipynb\n",
        "# Se√ß√µes:\n",
        "# 1. Setup e Imports\n",
        "# 2. Carregamento do Dataset\n",
        "# 3. Opera√ß√£o 1: An√°lise Explorat√≥ria e Tratamento\n",
        "# 4. Opera√ß√£o 2: Sele√ß√£o de Colunas Samsung\n",
        "# 5. Opera√ß√£o 3: An√°lise de Inconsist√™ncias\n",
        "# 6. Salvamento dos Dados Processados\n",
        "# 7. Relat√≥rio de Execu√ß√£o"
      ],
      "metadata": {
        "id": "fnLH4xlY-VFY"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "s1Zj7FC0qeIt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "65394616-1c03-43d3-a24a-627ab2f73623"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Notebook: Operacoes_1_2_3_Tratamento_Dados.ipynb\n",
        "# ==================================================\n",
        "\n",
        "# 1. SETUP INICIAL\n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Mount Drive\n",
        "drive.mount('/content/drive')\n",
        "BASE_PATH = '/content/drive/MyDrive/PLN_B2W_Reviews'\n",
        "\n",
        "# Criar estrutura se n√£o existir\n",
        "import os\n",
        "for folder in ['data/raw', 'data/processed', 'results/analysis']:\n",
        "    os.makedirs(f\"{BASE_PATH}/{folder}\", exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. DOWNLOAD DO DATASET\n",
        "!wget -O /content/drive/MyDrive/PLN/PLN_B2W_Reviews/data/raw/B2W-Reviews01.csv\n",
        "BASE_PATH = \"/content/drive/MyDrive/PLN/PLN_B2W_Reviews\"\n",
        "# 3. CARREGAMENTO E PRIMEIRA AN√ÅLISE\n",
        "df = pd.read_csv(f'{BASE_PATH}/data/raw/B2W-Reviews01.csv')\n",
        "print(f\"üìä Dataset carregado: {df.shape[0]:,} linhas x {df.shape[1]} colunas\")\n",
        "print(f\"üìã Colunas: {list(df.columns)}\")\n",
        "\n",
        "\n",
        "df.info()"
      ],
      "metadata": {
        "id": "Yb44kdR5sLXi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "90f323b8-c9e8-4938-bef1-7d90822ac4a2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "wget: missing URL\n",
            "Usage: wget [OPTION]... [URL]...\n",
            "\n",
            "Try `wget --help' for more options.\n",
            "üìä Dataset carregado: 132,373 linhas x 14 colunas\n",
            "üìã Colunas: ['submission_date', 'reviewer_id', 'product_id', 'product_name', 'product_brand', 'site_category_lv1', 'site_category_lv2', 'review_title', 'overall_rating', 'recommend_to_a_friend', 'review_text', 'reviewer_birth_year', 'reviewer_gender', 'reviewer_state']\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 132373 entries, 0 to 132372\n",
            "Data columns (total 14 columns):\n",
            " #   Column                 Non-Null Count   Dtype  \n",
            "---  ------                 --------------   -----  \n",
            " 0   submission_date        132373 non-null  object \n",
            " 1   reviewer_id            132373 non-null  object \n",
            " 2   product_id             132373 non-null  object \n",
            " 3   product_name           132289 non-null  object \n",
            " 4   product_brand          40982 non-null   object \n",
            " 5   site_category_lv1      132367 non-null  object \n",
            " 6   site_category_lv2      128360 non-null  object \n",
            " 7   review_title           132071 non-null  object \n",
            " 8   overall_rating         132373 non-null  int64  \n",
            " 9   recommend_to_a_friend  132355 non-null  object \n",
            " 10  review_text            129098 non-null  object \n",
            " 11  reviewer_birth_year    126389 non-null  float64\n",
            " 12  reviewer_gender        128237 non-null  object \n",
            " 13  reviewer_state         128382 non-null  object \n",
            "dtypes: float64(1), int64(1), object(12)\n",
            "memory usage: 14.1+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- An√°lise e Tratamento do Dataset ---\n",
        "print(\"\\n--- 3. Opera√ß√£o 1: An√°lise e Tratamento dos Campos ---\")\n",
        "\n",
        "# Verifica√ß√£o de valores ausentes (NaN) em cada coluna\n",
        "print(\"\\nüìä Valores Ausentes (NaN) por Coluna:\")\n",
        "nan_counts = df.isnull().sum()\n",
        "nan_counts_df = pd.DataFrame(nan_counts, columns=['NaN Count'])\n",
        "nan_counts_df['Percentage (%)'] = (nan_counts / len(df)) * 100\n",
        "print(nan_counts_df)\n",
        "\n",
        "# Remover a coluna 'review_text_translated' por possuir muitos valores NaN e n√£o ser relevante para a tarefa.\n",
        "if 'review_text_translated' in df.columns:\n",
        "    df = df.drop(columns=['review_text_translated'])\n",
        "    print(\"\\n‚úÖ Coluna 'review_text_translated' removida.\")\n",
        "\n",
        "# An√°lise de valores inv√°lidos ou inconsistentes em colunas espec√≠ficas\n",
        "print(\"\\nüîç Verifica√ß√£o de Valores Inv√°lidos ou Inconsistentes por Coluna:\")\n",
        "\n",
        "# 1. review_id: Verificar se h√° IDs duplicados, pois cada ID deve ser √∫nico.\n",
        "if df['reviewer_id'].nunique() < len(df['reviewer_id']):\n",
        "    print(f\"‚ö†Ô∏è Aten√ß√£o: A coluna 'reviewer_id' cont√©m {len(df['reviewer_id']) - df['reviewer_id'].nunique()} IDs duplicados. Isso pode indicar inconsist√™ncia nos dados.\")\n",
        "    # Dependendo da an√°lise, voc√™ pode querer remover duplicatas ou investigar mais a fundo.\n",
        "\n",
        "# 2. product_id: Verificar se h√° valores ausentes.\n",
        "if df['product_id'].isnull().sum() > 0:\n",
        "    print(f\"‚ö†Ô∏è Aten√ß√£o: A coluna 'product_id' cont√©m valores ausentes. N√∫mero de NaN: {df['product_id'].isnull().sum()}\")\n",
        "\n",
        "# 3. overall_rating: Verificar se os valores est√£o no intervalo de 1 a 5.\n",
        "invalid_ratings = df[~df['overall_rating'].isin(range(1, 6))]\n",
        "if not invalid_ratings.empty:\n",
        "    print(f\"‚ö†Ô∏è Aten√ß√£o: A coluna 'overall_rating' cont√©m {len(invalid_ratings)} valores fora do intervalo 1-5. Primeiros 5 valores inv√°lidos:\")\n",
        "    print(invalid_ratings['overall_rating'].head())\n",
        "\n",
        "# 4. recommend_to_a_friend: Verificar se os valores s√£o apenas 'Yes' ou 'No'.\n",
        "unique_recommend = df['recommend_to_a_friend'].unique()\n",
        "if not set(unique_recommend).issubset({'Yes', 'No', np.nan}):\n",
        "    print(f\"‚ö†Ô∏è Aten√ß√£o: A coluna 'recommend_to_a_friend' cont√©m valores diferentes de 'Yes', 'No' ou NaN. Valores encontrados: {unique_recommend}\")\n",
        "\n",
        "# 5. reviewer_gender: Verificar se os valores s√£o apenas 'M' ou 'F'.\n",
        "unique_genders = df['reviewer_gender'].unique()\n",
        "if not set(unique_genders).issubset({'M', 'F', np.nan}):\n",
        "    print(f\"‚ö†Ô∏è Aten√ß√£o: A coluna 'reviewer_gender' cont√©m valores diferentes de 'M', 'F' ou NaN. Valores encontrados: {unique_genders}\")\n",
        "    # Preencher valores ausentes para garantir consist√™ncia\n",
        "    df['reviewer_gender'] = df['reviewer_gender'].fillna('N√£o Informado')\n",
        "    print(\"Valores ausentes em 'reviewer_gender' preenchidos com 'N√£o Informado'.\")\n",
        "    print(f\"Novos valores √∫nicos na coluna 'reviewer_gender': {df['reviewer_gender'].unique()}\")\n",
        "\n",
        "# 6. reviewer_birth_year: Verificar se h√° anos de nascimento inv√°lidos (no futuro ou muito no passado).\n",
        "current_year = 2025\n",
        "invalid_years = df[(df['reviewer_birth_year'] < 1925) | (df['reviewer_birth_year'] > current_year)]\n",
        "if not invalid_years.empty:\n",
        "    print(f\"‚ö†Ô∏è Aten√ß√£o: A coluna 'reviewer_birth_year' cont√©m {len(invalid_years)} anos de nascimento inconsistentes (menores que 1925 ou maiores que {current_year}).\")\n",
        "    # Dependendo da pol√≠tica de tratamento, voc√™ pode remover ou preencher esses valores.\n",
        "\n",
        "print(\"\\n‚úÖ Etapa 1: An√°lise e Tratamento de Dados conclu√≠da. Inconsist√™ncias identificadas e colunas n√£o relevantes removidas.\")\n",
        "\n",
        "print(\"\\n--- Informa√ß√µes do DataFrame Ap√≥s o Tratamento ---\")\n",
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZekiNJ0PBxqo",
        "outputId": "3d2662f3-d9e4-4d6a-f054-2282c1241639"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- 3. Opera√ß√£o 1: An√°lise e Tratamento dos Campos ---\n",
            "\n",
            "üìä Valores Ausentes (NaN) por Coluna:\n",
            "                       NaN Count  Percentage (%)\n",
            "submission_date                0        0.000000\n",
            "reviewer_id                    0        0.000000\n",
            "product_id                     0        0.000000\n",
            "product_name                  84        0.063457\n",
            "product_brand              91391       69.040514\n",
            "site_category_lv1              6        0.004533\n",
            "site_category_lv2           4013        3.031585\n",
            "review_title                 302        0.228143\n",
            "overall_rating                 0        0.000000\n",
            "recommend_to_a_friend         18        0.013598\n",
            "review_text                 3275        2.474069\n",
            "reviewer_birth_year         5984        4.520559\n",
            "reviewer_gender             4136        3.124504\n",
            "reviewer_state              3991        3.014965\n",
            "\n",
            "üîç Verifica√ß√£o de Valores Inv√°lidos ou Inconsistentes por Coluna:\n",
            "‚ö†Ô∏è Aten√ß√£o: A coluna 'reviewer_id' cont√©m 19380 IDs duplicados. Isso pode indicar inconsist√™ncia nos dados.\n",
            "‚ö†Ô∏è Aten√ß√£o: A coluna 'reviewer_birth_year' cont√©m 67 anos de nascimento inconsistentes (menores que 1925 ou maiores que 2025).\n",
            "\n",
            "‚úÖ Etapa 1: An√°lise e Tratamento de Dados conclu√≠da. Inconsist√™ncias identificadas e colunas n√£o relevantes removidas.\n",
            "\n",
            "--- Informa√ß√µes do DataFrame Ap√≥s o Tratamento ---\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 132373 entries, 0 to 132372\n",
            "Data columns (total 14 columns):\n",
            " #   Column                 Non-Null Count   Dtype  \n",
            "---  ------                 --------------   -----  \n",
            " 0   submission_date        132373 non-null  object \n",
            " 1   reviewer_id            132373 non-null  object \n",
            " 2   product_id             132373 non-null  object \n",
            " 3   product_name           132289 non-null  object \n",
            " 4   product_brand          40982 non-null   object \n",
            " 5   site_category_lv1      132367 non-null  object \n",
            " 6   site_category_lv2      128360 non-null  object \n",
            " 7   review_title           132071 non-null  object \n",
            " 8   overall_rating         132373 non-null  int64  \n",
            " 9   recommend_to_a_friend  132355 non-null  object \n",
            " 10  review_text            129098 non-null  object \n",
            " 11  reviewer_birth_year    126389 non-null  float64\n",
            " 12  reviewer_gender        128237 non-null  object \n",
            " 13  reviewer_state         128382 non-null  object \n",
            "dtypes: float64(1), int64(1), object(12)\n",
            "memory usage: 14.1+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Continua√ß√£o do Tratamento de Dados ---\n",
        "print(\"\\n--- 3. Opera√ß√£o 1: Refinamento do Tratamento ---\")\n",
        "\n",
        "# 1. Tratamento de IDs de revisores duplicados\n",
        "# Embora a duplica√ß√£o de 'reviewer_id' seja normal (um usu√°rio pode fazer v√°rios reviews),\n",
        "# a duplica√ß√£o completa de linhas pode ser um erro. Vamos remover duplicatas exatas.\n",
        "df_no_duplicates = df.drop_duplicates().copy()\n",
        "print(f\"\\n‚úÖ Foram removidas {len(df) - len(df_no_duplicates)} linhas duplicadas exatas do dataset.\")\n",
        "df = df_no_duplicates\n",
        "\n",
        "# 2. Tratamento de anos de nascimento inconsistentes\n",
        "df['reviewer_birth_year'] = df['reviewer_birth_year'].apply(\n",
        "    lambda x: x if 1900 <= x <= 2025 else pd.NA\n",
        ")\n",
        "print(f\"‚úÖ Anos de nascimento inconsistentes substitu√≠dos por NaN.\")\n",
        "\n",
        "# 3. Tratamento de valores ausentes (NaN) nas colunas essenciais\n",
        "df.dropna(subset=['review_text', 'overall_rating', 'recommend_to_a_friend'], inplace=True)\n",
        "print(f\"\\n‚úÖ Linhas com valores ausentes nas colunas 'review_text', 'overall_rating' e 'recommend_to_a_friend' foram removidas.\")\n",
        "\n",
        "print(\"\\n‚úÖ Refinamento do tratamento conclu√≠do.\")\n",
        "\n",
        "print(\"\\n--- Informa√ß√µes do DataFrame Ap√≥s o Refinamento do Tratamento ---\")\n",
        "df.info()"
      ],
      "metadata": {
        "id": "a3Up5DbvNBb6",
        "outputId": "f7ff0c5b-1f7d-4cf1-8221-9870aaf1fc71",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- 3. Opera√ß√£o 1: Refinamento do Tratamento ---\n",
            "\n",
            "‚úÖ Foram removidas 955 linhas duplicadas exatas do dataset.\n",
            "‚úÖ Anos de nascimento inconsistentes substitu√≠dos por NaN.\n",
            "\n",
            "‚úÖ Linhas com valores ausentes nas colunas 'review_text', 'overall_rating' e 'recommend_to_a_friend' foram removidas.\n",
            "\n",
            "‚úÖ Refinamento do tratamento conclu√≠do.\n",
            "\n",
            "--- Informa√ß√µes do DataFrame Ap√≥s o Refinamento do Tratamento ---\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 128208 entries, 0 to 132372\n",
            "Data columns (total 14 columns):\n",
            " #   Column                 Non-Null Count   Dtype \n",
            "---  ------                 --------------   ----- \n",
            " 0   submission_date        128208 non-null  object\n",
            " 1   reviewer_id            128208 non-null  object\n",
            " 2   product_id             128208 non-null  object\n",
            " 3   product_name           128148 non-null  object\n",
            " 4   product_brand          40040 non-null   object\n",
            " 5   site_category_lv1      128202 non-null  object\n",
            " 6   site_category_lv2      124361 non-null  object\n",
            " 7   review_title           127982 non-null  object\n",
            " 8   overall_rating         128208 non-null  int64 \n",
            " 9   recommend_to_a_friend  128208 non-null  object\n",
            " 10  review_text            128208 non-null  object\n",
            " 11  reviewer_birth_year    122466 non-null  object\n",
            " 12  reviewer_gender        124260 non-null  object\n",
            " 13  reviewer_state         124401 non-null  object\n",
            "dtypes: int64(1), object(13)\n",
            "memory usage: 14.7+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Sele√ß√£o de Colunas e Filtragem ---\n",
        "print(\"\\n--- 4. Opera√ß√£o 2: Sele√ß√£o de Colunas Samsung ---\")\n",
        "\n",
        "# Lista de colunas relevantes, conforme a instru√ß√£o.\n",
        "colunas_relevantes = [\"review_text\", \"overall_rating\", \"recommend_to_a_friend\", \"product_brand\"]\n",
        "\n",
        "# Filtra o DataFrame para manter apenas as colunas relevantes e a marca 'Samsung'\n",
        "df_samsung = df[df['product_brand'].str.contains('Samsung', case=False, na=False)][colunas_relevantes].copy()\n",
        "\n",
        "# Remove a coluna 'product_brand' ap√≥s a filtragem, pois n√£o √© mais necess√°ria\n",
        "df_samsung = df_samsung.drop(columns=['product_brand'])\n",
        "\n",
        "print(f\"\\nüìä DataFrame com reviews da marca 'Samsung' criado: {df_samsung.shape[0]:,} linhas x {df_samsung.shape[1]} colunas\")\n",
        "print(f\"üìã Novas colunas: {list(df_samsung.columns)}\")\n",
        "\n",
        "# Exibe as primeiras 5 linhas para ver o resultado do filtro\n",
        "print(\"\\nPrimeiras 5 linhas do novo DataFrame (Samsung):\")\n",
        "print(df_samsung.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t0yV-QNuCsLk",
        "outputId": "1361fb91-a7f0-48da-86cd-5c6e0f99b905"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- 4. Opera√ß√£o 2: Sele√ß√£o de Colunas Samsung ---\n",
            "\n",
            "üìä DataFrame com reviews da marca 'Samsung' criado: 5,896 linhas x 3 colunas\n",
            "üìã Novas colunas: ['review_text', 'overall_rating', 'recommend_to_a_friend']\n",
            "\n",
            "Primeiras 5 linhas do novo DataFrame (Samsung):\n",
            "                                          review_text  overall_rating  \\\n",
            "29  Uma tela impec√°vel. Se sua prioridade √© tela e...               4   \n",
            "37  Melhor custo benef√≠cio. Exatamente  como anunc...               5   \n",
            "56  Muito √∫til, para pesquisas e baixar publica√ß√µe...               5   \n",
            "75  A entrega sempre no prazo e muitas vezes at√© a...               4   \n",
            "98  Recomendo tanto o produto quanto a loja, produ...               4   \n",
            "\n",
            "   recommend_to_a_friend  \n",
            "29                   Yes  \n",
            "37                   Yes  \n",
            "56                   Yes  \n",
            "75                   Yes  \n",
            "98                   Yes  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- An√°lise de Inconsist√™ncias ---\n",
        "print(\"\\n--- 5. Opera√ß√£o 3: An√°lise de Inconsist√™ncias ---\")\n",
        "\n",
        "# An√°lise de inconsist√™ncias: notas 1 e 2 com recomenda√ß√£o 'Yes'\n",
        "inconsistencias_ruins = df_samsung[(df_samsung['overall_rating'].isin([1, 2])) & (df_samsung['recommend_to_a_friend'] == 'Yes')]\n",
        "print(f\"\\nInconsist√™ncias (nota 1 ou 2, mas recomendou 'Yes'): {inconsistencias_ruins.shape[0]} registros\")\n",
        "print(inconsistencias_ruins.head())\n",
        "\n",
        "# An√°lise de inconsist√™ncias: notas 4 e 5 com recomenda√ß√£o 'No'\n",
        "inconsistencias_boas = df_samsung[(df_samsung['overall_rating'].isin([4, 5])) & (df_samsung['recommend_to_a_friend'] == 'No')]\n",
        "print(f\"Inconsist√™ncias (nota 4 ou 5, mas n√£o recomendou 'No'): {inconsistencias_boas.shape[0]} registros\")\n",
        "print(inconsistencias_boas.head())\n",
        "\n",
        "# Remo√ß√£o das inconsist√™ncias para garantir a coer√™ncia dos dados\n",
        "# Combina as condi√ß√µes para remover ambos os tipos de inconsist√™ncias em uma √∫nica opera√ß√£o\n",
        "df_samsung_clean = df_samsung[~((df_samsung['overall_rating'].isin([1, 2]) & (df_samsung['recommend_to_a_friend'] == 'Yes')) |\n",
        "                                ((df_samsung['overall_rating'].isin([4, 5]) & (df_samsung['recommend_to_a_friend'] == 'No'))))].copy()\n",
        "\n",
        "# A coluna 'recommend_to_a_friend' deve ser removida antes de come√ßar a modelagem\n",
        "# pois a coluna 'overall_rating' j√° capta a inten√ß√£o do usu√°rio\n",
        "# o mesmo review n√£o pode ser representado por duas classes diferentes\n",
        "# ou seja, se a 'overall_rating' for 4, 'recommend_to_a_friend' deveria ser 'Yes' (o que j√° foi tratado)\n",
        "\n",
        "print(f\"\\n‚úÖ DataFrame ap√≥s a remo√ß√£o de inconsist√™ncias: {df_samsung_clean.shape[0]:,} linhas\")\n",
        "print(\"As inconsist√™ncias foram removidas para coer√™ncia entre a nota e a recomenda√ß√£o.\")\n",
        "print(\"\\n--- Informa√ß√µes do DataFrame Ap√≥s a Limpeza ---\")\n",
        "df_samsung_clean.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kYcloTZzCvjY",
        "outputId": "728fea23-0190-4981-bad7-348032051b32"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- 5. Opera√ß√£o 3: An√°lise de Inconsist√™ncias ---\n",
            "\n",
            "Inconsist√™ncias (nota 1 ou 2, mas recomendou 'Yes'): 79 registros\n",
            "                                             review_text  overall_rating  \\\n",
            "873    O celular √© bom, por√©m tem muita interfer√™ncia...               2   \n",
            "5358   Produto bem embalado e chegou antes do prazo, ...               1   \n",
            "6601   Este √© o terceiro Samsung Galaxy que eu compro...               2   \n",
            "11405  Bom dia! A bateria descarrega r√°pida e o tecla...               2   \n",
            "13942  Efetuei a compra desse oculos pekosite da Amer...               1   \n",
            "\n",
            "      recommend_to_a_friend  \n",
            "873                     Yes  \n",
            "5358                    Yes  \n",
            "6601                    Yes  \n",
            "11405                   Yes  \n",
            "13942                   Yes  \n",
            "Inconsist√™ncias (nota 4 ou 5, mas n√£o recomendou 'No'): 64 registros\n",
            "                                            review_text  overall_rating  \\\n",
            "432   O produto √© excelente por√©m o aparelho que rec...               5   \n",
            "1772  Maravilhoso n√£o precisa de mudar em nada, comp...               5   \n",
            "2751  Gostei do produto,√© √≥timo.Mais moderno,mais di...               4   \n",
            "3860  Chegou antes do esperado e era do jeito que eu...               5   \n",
            "9462  √â um √≥timo celular, principalmente a quest√£o d...               5   \n",
            "\n",
            "     recommend_to_a_friend  \n",
            "432                     No  \n",
            "1772                    No  \n",
            "2751                    No  \n",
            "3860                    No  \n",
            "9462                    No  \n",
            "\n",
            "‚úÖ DataFrame ap√≥s a remo√ß√£o de inconsist√™ncias: 5,753 linhas\n",
            "As inconsist√™ncias foram removidas para garantir a coer√™ncia entre a nota e a recomenda√ß√£o.\n",
            "\n",
            "--- Informa√ß√µes do DataFrame Ap√≥s a Limpeza ---\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 5753 entries, 29 to 132318\n",
            "Data columns (total 3 columns):\n",
            " #   Column                 Non-Null Count  Dtype \n",
            "---  ------                 --------------  ----- \n",
            " 0   review_text            5753 non-null   object\n",
            " 1   overall_rating         5753 non-null   int64 \n",
            " 2   recommend_to_a_friend  5753 non-null   object\n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 179.8+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Salvamento dos Dados Processados\n",
        "# ==================================================\n",
        "import sys\n",
        "import os\n",
        "\n",
        "# Define o caminho base\n",
        "BASE_PATH = '/content/drive/MyDrive/PLN/PLN_B2W_Reviews'\n",
        "\n",
        "# Adiciona a pasta 'utils' ao caminho do sistema para poder importar\n",
        "sys.path.append(os.path.join(BASE_PATH, 'utils'))\n",
        "\n",
        "# Importa a fun√ß√£o do seu m√≥dulo\n",
        "from utils import save_dataframe_to_csv\n",
        "\n",
        "# Chama a fun√ß√£o de salvamento para o DataFrame limpo\n",
        "print(\"\\n--- 6. Salvamento dos Dados Processados ---\")\n",
        "save_dataframe_to_csv(\n",
        "    df=df_samsung_clean,\n",
        "    folder='data/processed',\n",
        "    file_name='b2w_reviews_samsung_cleaned.csv',\n",
        "    base_path=BASE_PATH\n",
        ")\n",
        "\n",
        "# 7. Relat√≥rio de Execu√ß√£o\n",
        "# ==================================================\n",
        "print(\"\\n--- 7. Relat√≥rio de Execu√ß√£o ---\")\n",
        "print(\"‚úÖ Todas as opera√ß√µes de tratamento, sele√ß√£o e limpeza de dados foram conclu√≠das e o DataFrame final foi salvo.\")\n",
        "print(f\"O arquivo final est√° localizado em: {os.path.join(BASE_PATH, 'data/processed', 'b2w_reviews_samsung_cleaned.csv')}\")"
      ],
      "metadata": {
        "id": "rgt69ZWwJIWD",
        "outputId": "c2b60715-62a0-4da0-d6e7-09a67dc440b6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- 6. Salvamento dos Dados Processados ---\n",
            "‚úÖ DataFrame salvo com sucesso em: /content/drive/MyDrive/PLN/PLN_B2W_Reviews/data/processed/b2w_reviews_samsung_cleaned.csv\n",
            "\n",
            "--- 7. Relat√≥rio de Execu√ß√£o ---\n",
            "‚úÖ Todas as opera√ß√µes de tratamento, sele√ß√£o e limpeza de dados foram conclu√≠das e o DataFrame final foi salvo.\n",
            "O arquivo final est√° localizado em: /content/drive/MyDrive/PLN/PLN_B2W_Reviews/data/processed/b2w_reviews_samsung_cleaned.csv\n"
          ]
        }
      ]
    }
  ]
}